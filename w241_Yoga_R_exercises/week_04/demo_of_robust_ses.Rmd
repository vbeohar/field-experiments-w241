---
title: "Week 4 Async Code"
author: "David Broockman (Hacked together by Alex Hughes)"
output:
  html_document:
    df_print: paged
---

# Benefits of Blocking
Remember the group variable from last week? Let's draw up another one of those, set up in the exact same way. 

```{r} 
set.seed(1414)

group <- c(rep("Man",20),rep("Woman",20))
```

Let's also built back a really simple function to randomize the order of treatment and controls, just like we had last week. 

```{r}
randomize <- function() { 
  sample(c(rep(0, 20), rep(1, 20)))
  } 
```
If we use this code to randomly assign treatment and control, then on average, the randomization assignments will mete out to be balanced, but of course there is no guarantee that this occurs for any particular instance. For example: 
```{r}
table(group, randomize())
table(group, randomize())
table(group, randomize())
```
In these tables, we have one randomization that assigned 8 of the treatment conditions to men, and two randomizations that assigned 11 of the treatment conditions to men (and the converse to women in all cases). 

Maybe this is ok. But maybe not. Here are two possible reasons that this might not be ok: 

1. It could be the case that for some **non-design** reason, we have a strong preference or incentive to have exactly the same number of units with some property in the treatment and control conditions. 
2. It could be the case that we want to increase the precision with which we estimate $\tau$, and so having a randomization that has very few units of one class in a group is an undesirable outcome. 

Let's define our function to estimate the ATE
```{r}
est_ate <- function(outcome, treat) { 
  mean(outcome[treat==1]) - mean(outcome[treat==0])
  } 
```
And as a bit more setup, let define a function `sim_normal_study` that sets up a series of potential outcomes to treatment and control (which are the same, AKA satisfy the sharp null hypothesis). (Again this week, we're talking about a study of eating soy and estrogen levels.) Our function then randomizes the study units and calculates the average treatment effect. All of this should be familiar from last weeks async and code. 

The additional step that we're including in this function is to count the number of women in the treatment arm of the study. 

```{r}
sim_normal_study <- function() {
  po_control <- c(seq(from = 1, to = 20), seq(from = 51, to = 70))
  po_treatment <- po_control
  treatment <- randomize()
  outcomes <- po_treatment * treatment + po_control * (1 - treatment)
  ate <- est_ate(outcomes, treatment)
  n_women_treatment <- table(group, treatment)[2, 2]
  return(list(ate = ate, n_women_treatment = n_women_treatment))
}
```

If we call this function once, the function returns back the estimated average treatment effect in the simulated study and the number of women that were assiged to treatment (out of the possible 20). 

```{r}
s1 <- sim_normal_study()
s1
```

In this case, we see that we calculate an ATE of `r s1$ate` and have `r s1$n_women_treatment` in the treatment condition. Fine. We don't learn much from a single instance, so let's [turn it up](http://www.nydailynews.com/entertainment/gossip/shia-labeouf-speaks-kimmel-drunken-cabaret-bust-video-article-1.1973651). 

```{r}
results <- t(replicate(1000, sim_normal_study()))
source("http://ischool.berkeley.edu/~d.alex.hughes/code/pubPlot.R")
plot(results, 
     main = "ATE and women in Treatment Condition", 
     xlab = "Average Treatment Effect", 
     ylab = "Women in Treatment")
abline(v = 0, col = "blue", lwd = 2)
``` 

We set the study up so that we *know* there is no treatment effect. And, when we have 10 women who we randomize into control we, indeed, recover this absense of an effect. Our estimates for the ATE seem pretty well centered around zero. 

But, there is a clearly linear relationship between the number of women that we have enrolled and our estimated ATE. If, through our simple random assignment procedure we sampled 12 of twenty women to be in the treatment condition -- which is pretty likely -- we would estimate an ATE of about 10! 

# More Blocking 
To address the problems of the last section, consider the following function called `randomize_blocked` that breaks the sample into two groups, *"blocks"*, and then performs the randomization within those groups. 

```{r} 
randomize_blocked <- function(){
  c(sample(c(rep(0, 10), rep(1, 10))), #group A
    sample(c(rep(0, 10), rep(1, 10)))) #group B
}
```

If we perform our randomization in this way, the groups are always balanced. 

```{r}
table(group, randomize_blocked())
table(group, randomize_blocked())
table(group, randomize_blocked())
``` 
## Question of Understanding 

1. Recreate the plot that we had previously, this time using the block randomized data. What has changed? Why is this a useful change to have occurred?
2. Does the restricted set of randomizations that we're realizing seem like "cheating"? Why or why not? 

```{r}

```



## Re-run the last experiment with blocking
If we re-run the soy/estrogen experiment/observation from the last section, but we explicitly block on the number of men and women that we randomize into treatment and control arms, what happens? 


```{r}
set.seed(7217)
po_control <- c(seq(from = 1, to = 20), seq(from = 51, to = 70))
po_treatment <- po_control + 10 #simulate effect of 10
treatment_blocked <- randomize_blocked()
outcomes_blocked <- po_treatment * treatment_blocked + po_control * (1- treatment_blocked)
ate <- est_ate(outcomes_blocked, treatment_blocked)
ate
```
Our estimated treatment effect is `r ate` and we know that the true $\tau$ is 10. Not bad. If we do this a large number of times, what does our distribution look like? 

Let's do this twice, once under simple randomization and another time under blocked randomization. Then, we'll compare the range of treatment effect that we find. 
```{r}
# First, under simple random assignment 
sim_normal_study <- function(){
  po_control <- c(seq(from = 1, to = 20), seq(from = 51, to = 70))
  po_treatment <- po_control
  treatment <- randomize()
  outcomes <- po_treatment * treatment + po_control * (1 - treatment)
  ate <- est_ate(outcomes, treatment)
  return(ate)
}

distribution_under_sharp_null <- replicate(5000, sim_normal_study())
# Second, under blocked random assignment 
distribution_under_sharp_null_blocked <- replicate(5000,
est_ate(outcomes_blocked, randomize_blocked()))

# Compare ranges 
source("http://ischool.berkeley.edu/~d.alex.hughes/code/pubPlot.R")
plot(density(distribution_under_sharp_null), 
     main = "Denisty of Outcomes", 
     lwd = 2, col="red", 
     ylim=c(0,.17))
#distribution without blocking
abline(v = ate, col = "blue")
mean(ate < distribution_under_sharp_null)
lines(density(distribution_under_sharp_null_blocked), 
      lwd = 2, col= "darkgreen")
legend("topright", legend = c("right", "wrong"), 
       lwd = c(2,2), lty = c(1,1), col = c("darkgreen", "red"))
#distribution with blocking
mean(ate < distribution_under_sharp_null_blocked)
```

## Similar gains when using regression
So far, we have talked about the gains only the framework of `ri`. Do we realize similar gains if we work from a regression framework too? Yep! 

```{r}
po_control <- c(seq(from = 1, to = 20), seq(from = 51, to = 70))
po_treatment <- po_control + 10 #simulate effect of 10
treatment <- randomize()
outcomes <- po_treatment * treatment + po_control * (1-treatment)

no_block_lm   <- lm(outcomes ~ treatment)
with_block_lm <- lm(outcomes ~ treatment + as.factor(group))

summary(no_block_lm)
summary(with_block_lm)
```

## Can we build back the unblocked, overall, estimate? 


# Clustering

Sometime there are design, practical, or ethical constrains that mean that although we can observe the outcome of treatment for each individual, we can't acutally *individually* assign each student to a treatment/control level. 

This leads to a bit of a trick situation -- we have observations occurring at one level, but assignment happening at another level. The least efficient solution would be to aggregate up to the highest level, but this throws away a lot of the information in our data when it rolls it into a first central moment. 

Instead, we can cluster our analysis. 

In the lecture, we present two examples: 

1. **School day length**: We can observe the schooling performance at the individaul level, but we can't randomly assign Timmy to have a long day and Tommy to have a short day. 
2. **Broadcast Advertising**: We can observe the purchasing behavior of each individual, but if we are making an ad-buy in *SF Weekly* we can't individually give Teddy more ads than Zach. 

In the remaining code, we'll operate as if we are dealing with the schooling example. 

```{r}
# Create classrooms 
n_classrooms <- 8
# Create students in classrooms 
n_students <- 16
``` 

With these parameters, we have `r n_classrooms * n_students` observations.  

```{r} 
classroom_ids0 <- unlist(lapply(1:n_classrooms, function(x) rep(x,times=n_students)))
classroom_ids0
``` 

David B. makes the point that the previous line of code might be a little tough to understand. Another, equivalent, and easier to comprehend way to do this task would be to call: 

```{r}
classroom_ids <- rep(1:n_classrooms, each = n_students)
classroom_ids
table(classroom_ids0 == classroom_ids)
``` 

We can pull the names of these clusters out by looking for the unique values in the classroom ids. 

```{r}
all_classrooms <- unique(classroom_ids)
all_classrooms
``` 

This is perhaps a little silly, since we're making the data ourselves, but it is actually nice for a more general case where we aren't creating the clusters as a sequence of numbers. Since we're making the data right now, we could instead make this list of clusters just by calling `1:n_classrooms` which would return `r 1:n_classrooms`. 

Here, we assign some classroom-level noise -- think of this as being located in the cool, or not-cool wings of the high-school.

```{r}
classroom_level_noise <- rnorm(n = length(all_classrooms), 
                               mean = 0, sd = 1)
classroom_level_noise
```

But of course, there is more noise in classroom-level outcomes than just the wing of the school the classroom is located. There is also noise that is associated with the individual *students* who are in the classrooom too! Let's build that in to the students. In the next lines, we create a student-level outcomes to control variable that is random noise at the individual level, **plus** random noise that was grouped at the classroom level. 

```{r}
student_outcomes_control <- rnorm(length(classroom_ids)) + classroom_level_noise[classroom_ids]
source("http://ischool.berkeley.edu/~d.alex.hughes/code/pubPlot.R")
plot(student_outcomes_control, col = classroom_ids, pch = 19, 
     main = "Student Outcomes Grouped \n By Classroom ",
     xlab = "Student ID", 
     ylab = "Student Outcome")
``` 

Let's add in a uniform treatment effect (this is the sharp treatment?). 

```{r}
student_outcomes_treat <- student_outcomes_control + 0.75
``` 

Alright! The data is set up. Or very nearly so. The last step here is to randomize at the classroom level.  Here, we write a little function that will create a vector of 1s and 0s (Treatment and Control) for those classrooms that are in the treatment condition. Since we're assigning in equal proporstions to treatment and control, we are going to sample the `all_classrooms` object and pick 1/2 of them to be in the treatment condition.

```{r}
randomize_clustered <- function() {
  treat_classroom_ids <- sample(x = all_classrooms, 
                                size = n_classrooms/2, 
                                replace = FALSE)
  return(as.numeric(classroom_ids %in% treat_classroom_ids))
}

randomize_clustered()
randomize_clustered()
randomize_clustered()
``` 

If you wanted to see the classroom ids next to these assigment vector, you could just hack the two `classroom_ids` and `randomize_clustered()` together using `table`. 

```{r}
table(randomize_clustered(), classroom_ids)
```

Now that we're sure it "works", let's actually make the treament assignment vector, and the potential outcomes to treatment and control. 

```{r}
treat <- randomize_clustered()
outcomes <- treat * student_outcomes_treat + (1-treat) * student_outcomes_control
``` 

With that in hand, we can easily calculate the ATE using the function we wrote earlier. 

```{r}
ate <- est_ate(outcomes, treat)
ate
``` 

And we find that the average treatment effect in this instance is `r ate`. But, what does the distribution of this ATE look like under the sharp null hypothesis? Recall that it is this comparison against the sharp null that we intent to use for making an informed statement about how likely this particular ATE was to occur by random chance. 

Like previous times, we calculate the ATE under a large number of random assignments to treatment and control. 

```{r}
distribution_under_sharp_null <- replicate(5000, est_ate(outcomes, randomize_clustered()))

source("http://ischool.berkeley.edu/~d.alex.hughes/code/pubPlot.R")
plot(density(distribution_under_sharp_null), 
     lwd = 2, col = "darkgreen",
     main = "Density under sharp null")
abline(v=ate, lwd = 2, col = "blue")
legend("topright", legend = c("right"), 
       lwd = 2, lty = 1, col = "darkgreen")


``` 

And we can pull out the p-value under the randomization inference framework by examineing the percent of the values that occur at a place that is smaller/larger than the p-value we observe using `mean(ate < distribution_under_sharp_null)` which evaluates to `r mean(ate < distribution_under_sharp_null)`. 

## What if we ignore clustering?

At this point -- after doing the reading and participating in the async material -- you might be thinking, "But guys, having to estimate the weighted ATE for every cluster, and then aggregate it back into an estimate for the whole popluation is hard. And that SE formula with groups? C'mon..."

And you're right, it is more work when we have grouping in our data that diverge from the case of simple random assignment across a homogeneous population. However, if you ignore the clustering that exists in your data, you may (read: "are likely to") badly misstate the treatment effect because your estimator undering ignoring the clustering is not guaranteed to be an unbiased estimator. 

Here we show this by creating a function that will randomize our data ignoring the classroom structure. 

```{r}
randomize_ignorning_clustering <- function() { 
  sample(c(rep(0,n_classrooms*n_students/2),
           rep(1,n_classrooms*n_students/2)) )
  }
randomize_ignorning_clustering()
``` 

Let's use the function to see how well/poorly we do! First, run through and replicate this assignment a large number of times.

```{r}
distribution_under_sharp_null_wrong <- replicate(5000,
est_ate(outcomes, randomize_ignorning_clustering()))
``` 

And plot the distribution. 

```{r}
source("http://ischool.berkeley.edu/~d.alex.hughes/code/pubPlot.R")
plot(density(distribution_under_sharp_null), 
     xlim = c(-3,3), ylim = c(0,2),
     lwd = 2, col = "darkgreen", 
     main = "Distribution of Estimated Treatment ")
lines(density(distribution_under_sharp_null_wrong), 
      lwd = 2, col = "red")
legend("topright", legend = c("right", "wrong"), 
       lwd = c(2,2), lty = c(1,1), col = c("darkgreen", "red"))
abline(v = ate, lwd = 2, col = "blue")
mean(ate < distribution_under_sharp_null_wrong) #p-value
``` 

Under the *wrong* setup, we have an innappropriately tight distribution surrounding the ATE under the sharp null. This will lead to us rejecting the null hypothesis that there is no effect in cases where we should *not* actually reject that null hypothesis. This is Type-1 error. 

Another way you might think about it is that if you fail to account for clustering, if you intend only commit Type-1 error in 5% of the cases by random chance (aka $\alpha = 0.05$), you will actually be committing an error at a much higher rate. 

Why does this happen? There are a number of reasons you might be innappropriately *too precise*. 

1. You're behaving as if you have `n` subjects, but you really have something that is much closer to `k` subjects where `k` is the number of clusters in your data. 
2. You're ignoring classroom level noise that might be leading to different outcomes. If there are different propinquities for some classrooms to do better, or have higher potential outcomes, then because you've got a small number of `k`, you're going to be wrong! 

```{r}
#No cluster level noise
source("http://ischool.berkeley.edu/~d.alex.hughes/code/pubPlot.R")
plot(density(replicate(5000, est_ate(rnorm(length(classroom_ids)),
randomize_clustered()))), 
  xlim = c(-2,2), 
  lwd = 2, col = "red", 
  main = "Density under correct and \n Incorrect Distribution") 
# include cluster level noise
lines(density(replicate(5000, est_ate(rnorm(length(classroom_ids)) +
classroom_level_noise[classroom_ids], randomize_clustered()))), 
  lwd = 2, col = "darkgreen")
legend("topright", legend = c("right", "wrong"), 
       lwd = c(2,2), lty = c(1,1), col = c("darkgreen", "red"))

```

# Continuing the Example Past Async
What if there are considerable cluster-level differences? What would one do then? For example, consider the following change to the data: Rather than cluster level differences being drawn from a normal distribution with $\mu = 0$, $\sigma = 1$, suppose that classroom level noise is drawn from a binomial distribution where hits are +5 units. 

```{r} 
set.seed(4)
classroom_level_noise <- 5 * rbinom(length(all_classrooms), 1, .25)

student_outcomes_control <-rnorm(length(classroom_ids)) + classroom_level_noise[classroom_ids]

source("http://ischool.berkeley.edu/~d.alex.hughes/code/pubPlot.R")
plot(student_outcomes_control, 
     col = classroom_ids, 
     pch = 19,
     main = "Student Outcomes Grouped \n By Classroom ",
     xlab = "Student ID",ylab = "Student Outcome")

treat <- randomize_clustered()
outcomes <- treat * student_outcomes_treat + (1-treat) * student_outcomes_control

ate <- est_ate(outcomes, treat)
ate

distribution_under_sharp_null <- replicate(5000, est_ate(outcomes, randomize_clustered()))

source("http://ischool.berkeley.edu/~d.alex.hughes/code/pubPlot.R")
plot(density(distribution_under_sharp_null), 
     lwd = 2, col = "darkgreen",
     main = "Density under sharp null")
abline(v=ate, lwd = 2, col = "blue")
legend("topright", legend = c("right"), 
       lwd = 2, lty = 1, col = "darkgreen")
``` 

# What is a person to do?? 

```{r}
simulate_bad_clustering <- function(
  number_clusters = 10, 
  tau = 1,
  number_simulations = 1000) { 

    d <- data.table(
      cluster_id = rep(LETTERS[1:number_clusters], times = 1:number_clusters), 
      cluster_offset = rep(1:number_clusters, times = 1:number_clusters),
      individual_offset = sequence(1:10)
    )

    d[ , po_control := cluster_offset + individual_offset]
    d[ , po_treat   := po_control + tau]

    ate <- rep(NA, number_simulations)

    for(i in 1:number_simulations) { 
      d[ , D := 0]
      d[sample(1:10, size=5, replace = FALSE), D := 1]
      d[ , Y := ifelse(D==1, po_control, po_treat)]

      ate[i] <- d[ , .(group_mean = mean(Y)), keyby = .(D)][ , diff(group_mean)]
    }

      par(mfrow = c(1,2))
      plot(d$po_control, pch = 19, col = 'steelblue')
      points(d$po_treat, pch = 19, col = 'darkorange')
      legend('topleft', 
             fill = c('steelblue', 'darkorange'), 
             legend=c('control', 'treat'))
      hist(ate, col = 'black')
}

simulate_bad_clustering(10)

```


```{r}
repeating_function <- function(stop_point) { 
    res_list <- sequence(1:10)
    res      <- unlist(res_list)

    return(res)
} 

repeating_function(5)
```

